---
title: "Chapter 10 Problems"
output: html_notebook
author: "Sasha Laundy"
---

# 10E1

If an event has probability 0.35, what are the log-odds of this event?

```{r}
log_odds <- function(prob) {
  log(prob / (1 - prob))
}

log_odds(p)
```

# 10E2

If an event has log-odds 3.2, what is the prob of this event?

```{r}
prob_from_log_odds <- function(odds_logged) {
  odds <- exp(odds_logged)
  odds / (1 + odds)
}

prob_from_log_odds(3.2)
```

And we can check our work: 

```{r}
log_odds(prob_from_log_odds(3.2))
```

# 10E3

Suppose that a coefficient in a logistic regression has value 1.7. What does this imply about the proportional change in odds of the outcome?

_It means that the log of the odds ratio is 1.7 times bigger for every unit of increase of the coefficient of interest._

# 10M1

As explained in the chapter, binomial data can be organized in aggregated and disaggregated forms, without any impact on inference. But the likelihood of the data does change when the data are converted between the two formats. Can you explain why?

_If you aggregate the (success, failure) counts down to a proportion of success, you can no longer tell how big the sample size is. 1 out of 2 looks the same as 1,000 out of 2,000, but from a likelihood perspective we are way less sure about the 50% of the former situation. So aggregating throws away information and is not advised by the author. 

# 10M3

Explain why the logit link is appropriate for a binomial generalized linear model. 

_In binomial models we're interested in predicting the probability of an outcome. Probabilities can be between 0 and 1. The logit function maps every possible value of our predictor variables to a value between 0 and 1. Additionally, it compresses the outcome space near 0 and 1. If your predictor is at 100 and your resulting probability is 98%, doubling the predictor value shouldn't lead to a doubling of probability. At that point you're almost guaranteed success, and increases to the predictor shouldn't change that very much._

# 10H3

Use the indicated records of salmon pirating attempts by bald eagles. While one eagle feeds, sometimes another will sweep in and try to steal the salmon fram it. Call the feeding eagle the "victim" and the thief the "pirate." Use the available data to build a binomial GLM of successful pirating attempts.

```{r}
library(tidyverse)
library(rethinking)
library(MASS)
data(eagles)
eagles
```
```{r}
cleaned_eagles <- eagles[c('y', 'n')]
cleaned_eagles$P <-ifelse(eagles$P == 'L', 1, 0)
cleaned_eagles$A <-ifelse(eagles$A == 'A', 1, 0)
cleaned_eagles$V <-ifelse(eagles$V == 'L', 1, 0)
```


## Part a

Fit the model on p 330 with `map` and `map2stan` and compare.



```{r}
m3.map <- rethinking::map(
  alist(
    y ~ dbinom(n, p),
    logit(p) <- a + bp * P + bv * V + ba * A,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 5),
    bv ~ dnorm(0, 5),
    ba ~ dnorm(0, 5)
  ),
  data = cleaned_eagles
)
precis(m3.map)
```
```{r}
m3.map2stan <- rethinking::map2stan(
  alist(
    y ~ dbinom(n, p),
    logit(p) <- a + bp * P + bv * V + ba * A,
    a ~ dnorm(0, 10),
    bp ~ dnorm(0, 5),
    bv ~ dnorm(0, 5),
    ba ~ dnorm(0, 5)
  ),
  data = eagles
)
precis(m3.map2stan)
```

## Part B

- Pick one of the models
- plot predicted prob of success at 89% interval for each row
- plot the predicted succes count and its 89% interval.
What dif info does ieach type of post pred provide?

```{r}

```

## Part C

Now try to improve the model. Consider an interaciton between the pirate's size and age. Compare this model to the provies one, using WAIC. Interpret. 
